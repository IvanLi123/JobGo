###################################
############# BASE
###################################
app.name=JobGo
server.port=8080
# 定位页面的目录到static/下
spring.mvc.view.prefix=/
spring.mvc.view.suffix=.html

#thymeleaf 配置
spring.thymeleaf.mode=HTML5
spring.thymeleaf.encoding=UTF-8
#缓存设置为false, 这样修改之后马上生效，便于调试
spring.thymeleaf.cache=false

###################################
############# MYSQL
###################################
# http://nml-cloud-231.cs.sfu.ca
#spring.datasource.url=jdbc:mysql://nml-cloud-231.cs.sfu.ca:3306/job_search?characterEncoding=UTF-8&useSSL=false
#spring.datasource.url=jdbc:mysql://nml-cloud-231.cs.sfu.ca:3306/job_search
#spring.datasource.username=dior
#spring.datasource.password=dior
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/job_search?characterEncoding=UTF-8&verifyServerCertificate=false&useSSL=false&requireSSL=false
spring.datasource.username=dior
spring.datasource.password=dior
#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

spring.jpa.properties.hibernate.hbm2ddl.auto=update
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5InnoDBDialect
spring.jpa.show-sql= true

spring.jpa.database-platform=org.hibernate.dialect.MySQL5Dialect
spring.jpa.hibernate.ddl-auto=update


###################################
############# RabbitMQ
###################################
spring.application.name=rabbitMQ-JobSearch
spring.rabbitmq.host=127.0.0.1
#spring.rabbitmq.host=gateway.sfucloud.ca
spring.rabbitmq.port=5672
spring.rabbitmq.username=hza89
spring.rabbitmq.password=dior
spring.rabbitmq.addresses=127.0.0.1:5672
#spring.rabbitmq.addresses=gateway.sfucloud.ca:5672
spring.rabbitmq.virtual-host=hza89_vhost

###################################
############# SPARK
###################################
#master.uri=spark://199.60.17.149:8020
sparkConfig.spark.home=/Users/mad/Documents/Software/spark-2.3.1-bin-hadoop2.7
sparkConfig.spark.network.timeout=10000000
sparkConfig.spark.executor.heartbeatInterval=10000000
sparkConfig.spark.authenticate=false
sparkConfig.spark.dynamicAllocation.enabled=true
sparkConfig.spark.dynamicAllocation.executorIdleTimeout=60
sparkConfig.spark.dynamicAllocation.cachedExecutorIdleTimeout=3600
sparkConfig.spark.dynamicAllocation.minExecutors=1
sparkConfig.spark.executor.instances=1
sparkConfig.spark.executor.memory=4g
sparkConfig.spark.dynamicAllocation.schedulerBacklogTimeout=1
sparkConfig.spark.port.maxRetries=32
sparkConfig.spark.eventLog.enabled=false
sparkConfig.spark.serializer=org.apache.spark.serializer.KryoSerializer
sparkConfig.spark.shuffle.service.enabled=true
sparkConfig.spark.shuffle.service.port=7337
sparkConfig.spark.eventLog.dir=hdfs://nml-cloud-149.cs.sfu.ca:8020/user/spark/applicationHistory
sparkConfig.spark.yarn.historyServer.address=http://nml-cloud-149.cs.sfu.ca:18088
sparkConfig.spark.yarn.jars=local:/home/envmodules/lib/spark-2.3.1-bin-hadoop2.7/jars/*
sparkConfig.spark.driver.extraLibraryPath=/opt/cloudera/parcels/CDH/lib/hadoop/lib/native
sparkConfig.spark.executor.extraLibraryPath=/opt/cloudera/parcels/CDH/lib/hadoop/lib/native
sparkConfig.spark.yarn.am.extraLibraryPath=/opt/cloudera/parcels/CDH/lib/hadoop/lib/native
sparkConfig.spark.yarn.config.gatewayPath=/opt/cloudera/parcels
sparkConfig.spark.yarn.config.replacementPath={{HADOOP_COMMON_HOME}}/../../..
sparkConfig.spark.master=local
sparkConfig.spark.submit.deployMode=client
sparkConfig.spark.dynamicAllocation.maxExecutors=40
sparkConfig.spark.sql.warehouse.dir=/user/hive/warehouse
#sparkConfig.spark.local.ip=127.0.0.1
#sparkConfig.spark.driver.host=localhost
#sparkConfig.spark.executorEnv.HADOOP_CONF_DIR=/opt/cloudera/parcels/CDH/lib/hadoop-yarn/etc/hadoop/
#sparkConfig.spark.executorEnv.YARN_CONF_DIR=/opt/cloudera/parcels/CDH/lib/hadoop-yarn/etc/hadoop/

#spark.props.driver.cores=1
#spark.props.driver.maxResultSize=1g
#spark.props.driver.memory=1g
#spark.props.local.dir=/tmp
#spark.streaming.duration=1000